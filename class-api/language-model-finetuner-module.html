
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AdaptNLP - An easy to use Natural Language Processing library and framework for predicting, training, fine-tuning, and serving up state-of-the-art NLP models.">
      
      
      
      
        <link rel="canonical" href="https://github.com/Novetta/adaptnlp/class-api/language-model-finetuner-module.html">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.0.3">
    
    
      
        <title>Language Model Fine-tuning Manual - AdaptNLP</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.1655a90d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.7fa14f5b.min.css">
        
          
          
          <meta name="theme-color" content="">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/custom.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="800" data-md-color-accent="green">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lmfinetuner" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-header__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AdaptNLP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Language Model Fine-tuning Manual
            
          </span>
        </div>
      </div>
    </div>
    <div class="md-header__options">
      
    </div>
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-nav__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    AdaptNLP
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        AdaptNLP Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        Tutorial - User Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Tutorial - User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorial - User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/index.html" class="md-nav__link">
        Tutorial - Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/token-tagging.html" class="md-nav__link">
        Token Tagging
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/sequence-classification.html" class="md-nav__link">
        Sequence Classification
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/embeddings.html" class="md-nav__link">
        Embeddings
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/question-answering.html" class="md-nav__link">
        Question Answering
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/summarization.html" class="md-nav__link">
        Summarization
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/translation.html" class="md-nav__link">
        Translation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/text-generation.html" class="md-nav__link">
        Text Generation
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        Advanced - User Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Advanced - User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Advanced - User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/advanced-index.html" class="md-nav__link">
        Advanced - Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/training-sequence-classification.html" class="md-nav__link">
        Training Sequence Classification
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/fine-tuning-language-model.html" class="md-nav__link">
        Fine Tuning Language Model
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../rest.html" class="md-nav__link">
        NLP Services with FastAPI
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      <label class="md-nav__link" for="__nav_5">
        Class API
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Class API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Class API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" >
      
      <label class="md-nav__link" for="__nav_5_1">
        NLP Tasks
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="NLP Tasks" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          NLP Tasks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="token-tagger-module.html" class="md-nav__link">
        Token Tagger
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="sequence-classifier-module.html" class="md-nav__link">
        Sequence Classifier
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="embeddings-module.html" class="md-nav__link">
        Embeddings
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="question-answering-module.html" class="md-nav__link">
        Question Answering
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="summarizer-module.html" class="md-nav__link">
        Summarizer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="translator-module.html" class="md-nav__link">
        Translator
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="text-generator-module.html" class="md-nav__link">
        Text Generator
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" checked>
      
      <label class="md-nav__link" for="__nav_5_2">
        Training and Fine-tuning
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Training and Fine-tuning" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Training and Fine-tuning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="sequence-classifier-trainer-module.html" class="md-nav__link">
        Sequence Classifier Trainer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="language-model-module.html" class="md-nav__link">
        Language Model Fine-tuning
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Language Model Fine-tuning Manual
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="language-model-finetuner-module.html" class="md-nav__link md-nav__link--active">
        Language Model Fine-tuning Manual
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lmfinetuner" class="md-nav__link">
    LMFineTuner
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../contributing.html" class="md-nav__link">
        Contributing
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lmfinetuner" class="md-nav__link">
    LMFineTuner
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Language Model Fine-tuning Manual</h1>
                
                <h2 id="lmfinetuner"><code>LMFineTuner</code><a class="headerlink" href="#lmfinetuner" title="Permanent link">&para;</a></h2>
<div class="autodoc">
<div class="autodoc-signature"><em>class </em><code>adaptnlp.<strong>LMFineTunerManual</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">train_data_file</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">eval_data_file=None</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">model_type='bert'</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">model_name_or_path=None</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">mlm=True</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">mlm_probability=0.15</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">config_name=None</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">tokenizer_name=None</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">cache_dir=None</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">block_size=-1</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">no_cuda=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">overwrite_cache=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">seed=42</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">fp16=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">fp16_opt_level='O1'</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">local_rank=-1</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>A Language Model Fine Tuner object you can set language model configurations and then train and evaluate</p>
<p>Usage:</p>
<div class="codehilite"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">finetuner</span> <span class="o">=</span> <span class="n">adaptnlp</span><span class="o">.</span><span class="n">LMFineTuner</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">finetuner</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<ul>
<li><strong>train_data_file</strong> - The input training data file (a text file).</li>
<li><strong>eval_data_file</strong> - An optional input evaluation data file to evaluate the perplexity on (a text file).</li>
<li><strong>model_type</strong> - The model architecture to be trained or fine-tuned.</li>
<li><strong>model_name_or_path</strong> - The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.</li>
<li><strong>mlm</strong> - Train with masked-language modeling loss instead of language modeling.</li>
<li><strong>mlm_probability</strong> - Ratio of tokens to mask for masked language modeling loss</li>
<li><strong>config_name</strong> - Optional Transformers pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.</li>
<li><strong>tokenizer_name</strong> - Optional Transformers pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.</li>
<li><strong>cache_dir</strong> - Optional directory to store the pre-trained models downloaded from s3 (If None, will go to default dir)</li>
<li><strong>block_size</strong> - Optional input sequence length after tokenization.
                    The training dataset will be truncated in block of this size for training."
                    <code>-1</code> will default to the model max input length for single sentence inputs (take into account special tokens).</li>
<li><strong>no_cuda</strong> - Avoid using CUDA when available</li>
<li><strong>overwrite_cache</strong> - Overwrite the cached training and evaluation sets</li>
<li><strong>seed</strong> - random seed for initialization</li>
<li><strong>fp16</strong> - Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit</li>
<li><strong>fp16_opt_level</strong> - For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].</li>
<li><strong>local_rank</strong> - For distributed training: local_rank</li>
</ul></div>
<div class="autodoc-members">
<div class="autodoc-signature"><code><strong>find_learning_rate</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">output_dir</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">file_name='learning_rate.tsv'</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">start_learning_rate=1e-07</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">end_learning_rate=10</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">iterations=100</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">mini_batch_size=8</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">stop_early=True</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">smoothing_factor=0.7</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">adam_epsilon=1e-08</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">weight_decay=0.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">**kwargs</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>Uses Leslie's cyclical learning rate finding method to generate and save the loss x learning rate plot</p>
<p>This method returns a suggested learning rate using the static method <code>LMFineTuner.suggest_learning_rate()</code>
which is implicitly run in this method.</p>
<ul>
<li><strong>output_dir</strong> - Path to dir for learning rate file to be saved</li>
<li><strong>file_name</strong> - Name of learning rate .tsv file</li>
<li><strong>start_learning_rate</strong> - Initial learning rate to start cyclical learning rate finder method</li>
<li><strong>end_learning_rate</strong> - End learning rate to stop exponential increase of the learning rate</li>
<li><strong>iterations</strong> - Number of optimizer iterations for the ExpAnnealLR scheduler</li>
<li><strong>mini_batch_size</strong> - Batch size for dataloader</li>
<li><strong>stop_early</strong> - Bool for stopping early once loss diverges</li>
<li><strong>smoothing_factor</strong> - Smoothing factor on moving average of losses</li>
<li><strong>adam_epsilon</strong> - Epsilon for Adam optimizer.</li>
<li><strong>weight_decay</strong> - Weight decay if we apply some.</li>
<li><strong>kwargs</strong> - Additional keyword arguments for the Adam optimizer
<strong>return</strong> - Learning rate as a float</li>
</ul></div>
<div class="autodoc-signature"><code><strong>suggest_learning_rate</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">losses</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">lrs</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">lr_diff=30</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">loss_threshold=0.05</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">adjust_value=1</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>Attempts to find the optimal learning rate using a interval slide rule approach with the cyclical learning rate method</p>
<ul>
<li><strong>losses</strong> - Numpy array of losses</li>
<li><strong>lrs</strong> - Numpy array of exponentially increasing learning rates (must match dim of <code>losses</code>)</li>
<li><strong>lr_diff</strong> - Learning rate Interval of slide ruler</li>
<li><strong>loss_threshold</strong> - Threshold of loss difference on interval where the sliding stops</li>
<li><strong>adjust_value</strong> - Coefficient for adjustment
<strong>return</strong> - the optimal learning rate as a float</li>
</ul></div>
<div class="autodoc-signature"><code><strong>train_one_cycle</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">output_dir</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">should_continue=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">overwrite_output_dir=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">evaluate_during_training=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">per_gpu_train_batch_size=4</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">gradient_accumulation_steps=1</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">learning_rate=5e-05</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">weight_decay=0.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">adam_epsilon=1e-08</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">max_grad_norm=1.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">num_train_epochs=1.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">max_steps=-1</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">warmup_steps=0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">logging_steps=50</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">save_steps=50</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">save_total_limit=3</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">use_tensorboard=False</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><ul>
<li><strong>output_dir</strong> - The output directory where the model predictions and checkpoints will be written.</li>
<li><strong>should_continue</strong> - Whether to continue training from latest checkpoint in <code>output_dir</code></li>
<li><strong>overwrite_output_dir</strong> - Overwrite the content of output directory <code>output_dir</code></li>
<li><strong>evaluate_during_training</strong> - Run evaluation during training at each <code>logging_step</code>.</li>
<li><strong>per_gpu_train_batch_size</strong> - Batch size per GPU/CPU for training. (If <code>evaluate_during_training</code> is True, this is also the eval batch size</li>
<li><strong>gradient_accumulation_steps</strong> - Number of updates steps to accumulate before performing a backward/update pass</li>
<li><strong>learning_rate</strong> - The initial learning rate for Adam optimizer.</li>
<li><strong>weight_decay</strong> - Weight decay if we apply some.</li>
<li><strong>adam_epsilon</strong> - Epsilon for Adam optimizer.</li>
<li><strong>max_grad_norm</strong> - Max gradient norm. Duh</li>
<li><strong>num_train_epochs</strong> - Total number of training epochs to perform.</li>
<li><strong>max_steps</strong> - If &gt; 0: set total number of training steps to perform. Override <code>num_train_epochs</code>.</li>
<li><strong>warmup_steps</strong> - Linear warmup over warmup_steps.</li>
<li><strong>logging_steps</strong> - Number of steps until logging occurs.</li>
<li><strong>save_steps</strong> - Number of steps until checkpoint is saved in <code>output_dir</code></li>
<li><strong>save_total_limit</strong> - Limit the total amount of checkpoints, delete the older checkpoints in the <code>output_dir</code>, does not delete by default</li>
<li><strong>use_tensorboard</strong> - Only useable if tensorboard is installed
<strong>return</strong> - None</li>
</ul></div>
<div class="autodoc-signature"><code><strong>train</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">output_dir</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">should_continue=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">overwrite_output_dir=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">evaluate_during_training=False</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">per_gpu_train_batch_size=4</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">gradient_accumulation_steps=1</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">learning_rate=5e-05</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">weight_decay=0.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">adam_epsilon=1e-08</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">max_grad_norm=1.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">num_train_epochs=1.0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">max_steps=-1</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">warmup_steps=0</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">logging_steps=50</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">save_steps=50</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">save_total_limit=3</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">use_tensorboard=False</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><ul>
<li><strong>output_dir</strong> - The output directory where the model predictions and checkpoints will be written.</li>
<li><strong>should_continue</strong> - Whether to continue training from latest checkpoint in <code>output_dir</code></li>
<li><strong>overwrite_output_dir</strong> - Overwrite the content of output directory <code>output_dir</code></li>
<li><strong>evaluate_during_training</strong> - Run evaluation during training at each <code>logging_step</code>.</li>
<li><strong>per_gpu_train_batch_size</strong> - Batch size per GPU/CPU for training. (If <code>evaluate_during_training</code> is True, this is also the eval batch size</li>
<li><strong>gradient_accumulation_steps</strong> - Number of updates steps to accumulate before performing a backward/update pass</li>
<li><strong>learning_rate</strong> - The initial learning rate for Adam optimizer.</li>
<li><strong>weight_decay</strong> - Weight decay if we apply some.</li>
<li><strong>adam_epsilon</strong> - Epsilon for Adam optimizer.</li>
<li><strong>max_grad_norm</strong> - Max gradient norm. Duh</li>
<li><strong>num_train_epochs</strong> - Total number of training epochs to perform.</li>
<li><strong>max_steps</strong> - If &gt; 0: set total number of training steps to perform. Override <code>num_train_epochs</code>.</li>
<li><strong>warmup_steps</strong> - Linear warmup over warmup_steps.</li>
<li><strong>logging_steps</strong> - Number of steps until logging occurs.</li>
<li><strong>save_steps</strong> - Number of steps until checkpoint is saved in <code>output_dir</code></li>
<li><strong>save_total_limit</strong> - Limit the total amount of checkpoints, delete the older checkpoints in the <code>output_dir</code>, does not delete by default</li>
<li><strong>use_tensorboard</strong> - Only useable if tensorboard is installed
<strong>return</strong> - None</li>
</ul></div>
<div class="autodoc-signature"><code><strong>evaluate</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">output_dir</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">per_gpu_eval_batch_size=4</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">prefix=''</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><ul>
<li><strong>output_dir</strong> - The output directory where the model predictions and checkpoints will be written.</li>
<li><strong>per_gpu_eval_batch_size</strong> - Batch size per GPU/CPU for evaluation.</li>
<li><strong>prefix</strong> - Prefix of checkpoint i.e. "checkpoint-50"
<strong>return</strong> - Results in a dictionary</li>
</ul></div>
<div class="autodoc-signature"><code><strong>evaluate_all_checkpoints</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">output_dir</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">per_gpu_eval_batch_size=4</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><ul>
<li><strong>output_dir</strong> - The output directory where the model predictions and checkpoints will be written.</li>
<li><strong>per_gpu_eval_batch_size</strong> - Batch size per GPU/CPU for evaluation.
<strong>return</strong> - Results in a dictionary</li>
</ul></div>
<div class="autodoc-signature"><code><strong>freeze</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>Freeze last classification layer group only</p></div>
<div class="autodoc-signature"><code><strong>unfreeze</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>Unfreeze all layers</p></div>
<div class="autodoc-signature"><code><strong>freeze_to</strong></code><span class="autodoc-punctuation">(</span><em class="autodoc-param">self</em><span class="autodoc-punctuation">, </span><em class="autodoc-param">n</em><span class="autodoc-punctuation">)</span></div>
<div class="autodoc-docstring"><p>Freeze first n layers of model</p>
<ul>
<li><strong>n</strong> - Starting from initial layer, freeze all layers up to nth layer inclusively</li>
</ul></div>
</div>
</div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="language-model-module.html" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Language Model Fine-tuning
            </div>
          </div>
        </a>
      
      
        <a href="../contributing.html" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Contributing
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fb4a9340.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.ca5457b8.min.js"></script>
      
    
  </body>
</html>