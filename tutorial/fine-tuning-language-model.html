
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="AdaptNLP - An easy to use Natural Language Processing library and framework for predicting, training, fine-tuning, and serving up state-of-the-art NLP models.">
      
      
      
      
        <link rel="canonical" href="https://github.com/Novetta/adaptnlp/tutorial/fine-tuning-language-model.html">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.0.3">
    
    
      
        <title>Fine Tuning Language Model - AdaptNLP</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.1655a90d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.7fa14f5b.min.css">
        
          
          
          <meta name="theme-color" content="">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/custom.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="800" data-md-color-accent="green">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#what-is-a-language-model" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-header__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AdaptNLP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Fine Tuning Language Model
            
          </span>
        </div>
      </div>
    </div>
    <div class="md-header__options">
      
    </div>
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://github.com/Novetta/adaptnlp" title="AdaptNLP" class="md-nav__button md-logo" aria-label="AdaptNLP">
      
  <img src="../img/NovettaAdaptNLP-mark-dark-100px.png" alt="logo">

    </a>
    AdaptNLP
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/Novetta/adaptnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Novetta/adaptnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        AdaptNLP Overview
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        Tutorial - User Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Tutorial - User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorial - User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        Tutorial - Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="token-tagging.html" class="md-nav__link">
        Token Tagging
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="sequence-classification.html" class="md-nav__link">
        Sequence Classification
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="embeddings.html" class="md-nav__link">
        Embeddings
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="question-answering.html" class="md-nav__link">
        Question Answering
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="summarization.html" class="md-nav__link">
        Summarization
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="translation.html" class="md-nav__link">
        Translation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="text-generation.html" class="md-nav__link">
        Text Generation
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        Advanced - User Guide
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Advanced - User Guide" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Advanced - User Guide
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="advanced-index.html" class="md-nav__link">
        Advanced - Intro
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="training-sequence-classification.html" class="md-nav__link">
        Training Sequence Classification
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
      <a href="fine-tuning-language-model.html" class="md-nav__link md-nav__link--active">
        Fine Tuning Language Model
      </a>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../rest.html" class="md-nav__link">
        NLP Services with FastAPI
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Class API
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Class API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Class API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" >
      
      <label class="md-nav__link" for="__nav_5_1">
        NLP Tasks
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="NLP Tasks" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          NLP Tasks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/token-tagger-module.html" class="md-nav__link">
        Token Tagger
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/sequence-classifier-module.html" class="md-nav__link">
        Sequence Classifier
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/embeddings-module.html" class="md-nav__link">
        Embeddings
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/question-answering-module.html" class="md-nav__link">
        Question Answering
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/summarizer-module.html" class="md-nav__link">
        Summarizer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/translator-module.html" class="md-nav__link">
        Translator
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/text-generator-module.html" class="md-nav__link">
        Text Generator
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
            
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" >
      
      <label class="md-nav__link" for="__nav_5_2">
        Training and Fine-tuning
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Training and Fine-tuning" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Training and Fine-tuning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/sequence-classifier-trainer-module.html" class="md-nav__link">
        Sequence Classifier Trainer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/language-model-module.html" class="md-nav__link">
        Language Model Fine-tuning
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../class-api/language-model-finetuner-module.html" class="md-nav__link">
        Language Model Fine-tuning Manual
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../contributing.html" class="md-nav__link">
        Contributing
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="what-is-a-language-model">What is a language model?<a class="headerlink" href="#what-is-a-language-model" title="Permanent link">&para;</a></h1>
<p><a href="https://colab.research.google.com/github/Novetta/adaptnlp/blob/master/tutorials/Finetuning%20and%20Training%20(Advanced)/Fine-tuning%20Language%20Model.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>Language modeling is the task of generating a probability distribution over a sequence of words. The language models that we are using can assign the probabilitiy of an upcoming word(s) given a sequence of words. The GPT2 language model is a good example of a <em>Causal Language Model</em> which can predict words following a sequence of words. This predicted word can then be used along the given sequence of words to predict another word and so on. This is how we actually a variant of how we produce models for the NLP task of text generation.</p>
<h1 id="why-would-you-want-to-fine-tune-a-language-model">Why would you want to fine-tune a language model?<a class="headerlink" href="#why-would-you-want-to-fine-tune-a-language-model" title="Permanent link">&para;</a></h1>
<p>Fine-tuning a language model comes in handy when data of a target task comes from a different distribution compared to the general-domain data that was used for pretraining a language model.</p>
<p>When fine-tuning the language model on data from a target task, the general-domain pretrained model is able to converge
quickly and adapt to the idiosyncrasies of the target data.  This can be seen from the efforts of ULMFiT and Jeremy
Howard's and Sebastian Ruder's approach on NLP transfer learning.</p>
<p>With AdaptNLP's <code>LMFineTuner</code>, we can start to fine-tune state-of-the-art pretrained transformers architecture 
language models provided by Hugging Face's Transformers library. <code>LMFineTuner</code> is built on <code>transformers.Trainer</code> so additional documentation on it can be found at Hugging Face's documentation <a href="https://huggingface.co/transformers/master/main_classes/trainer.html">here</a></p>
<p>Below are the available transformers language models for fine-tuning with <code>LMFineTuner</code></p>
<table>
<thead>
<tr>
<th>Transformer Model</th>
<th>Model Type/Architecture String Key</th>
</tr>
</thead>
<tbody>
<tr>
<td>ALBERT</td>
<td>"albert"</td>
</tr>
<tr>
<td>DistilBERT</td>
<td>"distilbert"</td>
</tr>
<tr>
<td>BERT</td>
<td>"bert"</td>
</tr>
<tr>
<td>CamemBERT</td>
<td>"camembert"</td>
</tr>
<tr>
<td>RoBERTa</td>
<td>"roberta"</td>
</tr>
<tr>
<td>GPT</td>
<td>"gpt"</td>
</tr>
<tr>
<td>GPT2</td>
<td>"gpt2"</td>
</tr>
</tbody>
</table>
<p>You can fine-tune on any transformers language models with the above architecture in Huggingface's Transformers
library.  Key shortcut names are located <a href="https://huggingface.co/transformers/pretrained_models.html">here</a>.</p>
<p>The same goes for Huggingface's public model-sharing repository, which is available <a href="https://huggingface.co/models">here</a>
as of v2.2.2 of the Transformers library.</p>
<p>This tutorial will go over the following simple-to-use componenets of using the <code>LMFineTuner</code> to fine-tune pre-trained language models on your custom text data.
1. Data loading and training arguments
2. Language model training
3. Language model evaluation</p>
<h1 id="1-data-loading-and-training-arguments">1. Data loading and training arguments<a class="headerlink" href="#1-data-loading-and-training-arguments" title="Permanent link">&para;</a></h1>
<p>We'll first start by downloading some example raw text files. If you want to fine-tune a model on your own custom data, just provide the file paths to the training and evaluation text files that contain text from your target task. You don't require a lot of formatting with the data since a language model does not necessarily require "labeled" data. All you need is the text you'd like use to "expand" the domain of knowledge that your language model is training on.</p>
<div class="codehilite"><pre><span></span><code><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">research</span><span class="o">.</span><span class="n">metamind</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">wikitext</span><span class="o">/</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>

<span class="n">train_file</span> <span class="o">=</span> <span class="s2">&quot;./wikitext-2-raw/wiki.train.raw&quot;</span>
<span class="n">eval_file</span> <span class="o">=</span> <span class="s2">&quot;./wikitext-2-raw/wiki.test.raw&quot;</span>
</code></pre></div>

<details class = "summary">
<summary>Output</summary>

<div class="codehilite"><pre><span></span><code>    <span class="o">--</span><span class="mi">2020</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">31</span> <span class="mi">15</span><span class="p">:</span><span class="mi">38</span><span class="p">:</span><span class="mi">50</span><span class="o">--</span>  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">research</span><span class="o">.</span><span class="n">metamind</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">wikitext</span><span class="o">/</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>
    <span class="n">Resolving</span> <span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span> <span class="p">(</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="p">)</span><span class="o">...</span> <span class="mf">52.217</span><span class="o">.</span><span class="mf">64.78</span>
    <span class="n">Connecting</span> <span class="n">to</span> <span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span> <span class="p">(</span><span class="n">s3</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="p">)</span><span class="o">|</span><span class="mf">52.217</span><span class="o">.</span><span class="mf">64.78</span><span class="o">|</span><span class="p">:</span><span class="mf">443.</span><span class="o">..</span> <span class="n">connected</span><span class="o">.</span>
    <span class="n">HTTP</span> <span class="n">request</span> <span class="n">sent</span><span class="p">,</span> <span class="n">awaiting</span> <span class="n">response</span><span class="o">...</span> <span class="mi">200</span> <span class="n">OK</span>
    <span class="n">Length</span><span class="p">:</span> <span class="mi">4721645</span> <span class="p">(</span><span class="mf">4.5</span><span class="n">M</span><span class="p">)</span> <span class="p">[</span><span class="n">application</span><span class="o">/</span><span class="nb">zip</span><span class="p">]</span>
    <span class="n">Saving</span> <span class="n">to</span><span class="p">:</span> <span class="err">‘</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span><span class="err">’</span>

    <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">z</span> <span class="mi">100</span><span class="o">%</span><span class="p">[</span><span class="o">===================&gt;</span><span class="p">]</span>   <span class="mf">4.50</span><span class="n">M</span>  <span class="mf">2.92</span><span class="n">MB</span><span class="o">/</span><span class="n">s</span>    <span class="ow">in</span> <span class="mf">1.5</span><span class="n">s</span>    

    <span class="mi">2020</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">31</span> <span class="mi">15</span><span class="p">:</span><span class="mi">38</span><span class="p">:</span><span class="mi">52</span> <span class="p">(</span><span class="mf">2.92</span> <span class="n">MB</span><span class="o">/</span><span class="n">s</span><span class="p">)</span> <span class="o">-</span> <span class="err">‘</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span><span class="err">’</span> <span class="n">saved</span> <span class="p">[</span><span class="mi">4721645</span><span class="o">/</span><span class="mi">4721645</span><span class="p">]</span>

    <span class="n">Archive</span><span class="p">:</span>  <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">-</span><span class="n">v1</span><span class="o">.</span><span class="n">zip</span>
       <span class="n">creating</span><span class="p">:</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span>
      <span class="n">inflating</span><span class="p">:</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span>  
      <span class="n">inflating</span><span class="p">:</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">raw</span>  
      <span class="n">inflating</span><span class="p">:</span> <span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">wiki</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">raw</span>  
</code></pre></div>


</details>

<p>Now that we have the text data we want to fine-tune our language model on, we can move on to configuring the training component.</p>
<p>One of the first things we'll need to specify before we start training are the training arguments. Training arguments consist mainly of the hyperparameters we want to provide the model. These may include batch size, initial learning rate, number of epochs, etc.</p>
<p>We will be using the <code>transformers.TrainingArguments</code> data class to store our training args. These are compatible with the <code>transformers.Trainer</code> as well as AdaptNLP's train methods. For more documention on the <code>TrainingArguments</code> class, please look <a href="https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments">here</a>. There are a lot of arguments available, but we will pass in the important args and use default values for the rest.</p>
<p>The training arguments below specify the output directory for you model and checkpoints. </p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;./models&#39;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">evaluate_during_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">logging_dir</span><span class="o">=</span><span class="s1">&#39;./logs&#39;</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">2500</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>
</code></pre></div>

<h1 id="2-language-model-training">2. Language model training<a class="headerlink" href="#2-language-model-training" title="Permanent link">&para;</a></h1>
<p>Now that we have our data and training arguments, let's instantiate the <code>LMFineTuner</code> and load in a pre-trained language model we would like to fine-tune. In this case, we will use the <code>gpt2</code> pre-trained language model.</p>
<p>Note: You can load in any model with the allowable architecture that we've specified above. You can even load in custom pre-trained models or models that you find in the Hugging Face repository that have already been fine-tuned and trained on NLP target tasks.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">LMFineTuner</span>

<span class="n">finetuner</span> <span class="o">=</span> <span class="n">LMFineTuner</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Now we can run the built-in <code>train()</code> method by passing in the training arguments. The training method will also be where you specify your data arguments which include the your train and eval datasets, the pre-trained model ID (this should have been loaded from your earlier cells, but can be loaded dynamically), text column name, label column name, and ordered label names (only required if loading in paths to CSV data file for dataset args).</p>
<p>Notice how we pass the <code>mlm</code> argument as False? The mlm argument should be true if we are using a masked language model variant such as BERT architecture language models. More information can be found on Hugging Face's documentation <a href="https://huggingface.co/transformers/master/task_summary.html#masked-language-modeling">here</a></p>
<p>Please checkout AdaptNLP's package reference for more information <a href="https://novetta.github.io/adaptnlp/class-api/language-model-module.html">here</a>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">finetuner</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">training_args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_file</span><span class="o">=</span><span class="n">eval_file</span><span class="p">,</span>
    <span class="n">eval_file</span><span class="o">=</span><span class="n">eval_file</span><span class="p">,</span>
    <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">overwrite_cache</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<details class = "summary">
<summary>Output</summary>

<div class="codehilite"><pre><span></span><code>    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">44</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">training_args</span> <span class="o">-</span>   <span class="n">PyTorch</span><span class="p">:</span> <span class="n">setting</span> <span class="n">up</span> <span class="n">devices</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">44</span> <span class="o">-</span> <span class="n">WARNING</span> <span class="o">-</span> <span class="n">adaptnlp</span><span class="o">.</span><span class="n">language_model</span> <span class="o">-</span>   <span class="n">Process</span> <span class="n">rank</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">device</span><span class="p">:</span> <span class="n">cuda</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">n_gpu</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">distributed</span> <span class="n">training</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                    <span class="mi">16</span><span class="o">-</span><span class="n">bits</span> <span class="n">training</span><span class="p">:</span> <span class="kc">False</span>

    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">44</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">adaptnlp</span><span class="o">.</span><span class="n">language_model</span> <span class="o">-</span>   <span class="n">Training</span><span class="o">/</span><span class="n">evaluation</span> <span class="n">parameters</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;output_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;./models&quot;</span><span class="p">,</span>
      <span class="s2">&quot;overwrite_output_dir&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;do_train&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;do_eval&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;do_predict&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;evaluate_during_training&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;per_device_eval_batch_size&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;per_gpu_train_batch_size&quot;</span><span class="p">:</span> <span class="n">null</span><span class="p">,</span>
      <span class="s2">&quot;per_gpu_eval_batch_size&quot;</span><span class="p">:</span> <span class="n">null</span><span class="p">,</span>
      <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">5e-05</span><span class="p">,</span>
      <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
      <span class="s2">&quot;adam_epsilon&quot;</span><span class="p">:</span> <span class="mf">1e-08</span><span class="p">,</span>
      <span class="s2">&quot;max_grad_norm&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
      <span class="s2">&quot;num_train_epochs&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;max_steps&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
      <span class="s2">&quot;logging_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;./logs&quot;</span><span class="p">,</span>
      <span class="s2">&quot;logging_first_step&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
      <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="mi">2500</span><span class="p">,</span>
      <span class="s2">&quot;save_total_limit&quot;</span><span class="p">:</span> <span class="n">null</span><span class="p">,</span>
      <span class="s2">&quot;no_cuda&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
      <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;fp16_opt_level&quot;</span><span class="p">:</span> <span class="s2">&quot;O1&quot;</span><span class="p">,</span>
      <span class="s2">&quot;local_rank&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;tpu_num_cores&quot;</span><span class="p">:</span> <span class="n">null</span><span class="p">,</span>
      <span class="s2">&quot;tpu_metrics_debug&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;debug&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;dataloader_drop_last&quot;</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
      <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
      <span class="s2">&quot;past_index&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">}</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">44</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">filelock</span> <span class="o">-</span>   <span class="n">Lock</span> <span class="mi">139826145788648</span> <span class="n">acquired</span> <span class="n">on</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">lock</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">44</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">language_modeling</span> <span class="o">-</span>   <span class="n">Creating</span> <span class="n">features</span> <span class="kn">from</span> <span class="nn">dataset</span> <span class="n">file</span> <span class="n">at</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">language_modeling</span> <span class="o">-</span>   <span class="n">Saving</span> <span class="n">features</span> <span class="n">into</span> <span class="n">cached</span> <span class="n">file</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span> <span class="p">[</span><span class="n">took</span> <span class="mf">0.004</span> <span class="n">s</span><span class="p">]</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">filelock</span> <span class="o">-</span>   <span class="n">Lock</span> <span class="mi">139826145788648</span> <span class="n">released</span> <span class="n">on</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">lock</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">filelock</span> <span class="o">-</span>   <span class="n">Lock</span> <span class="mi">139826145788312</span> <span class="n">acquired</span> <span class="n">on</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">lock</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">language_modeling</span> <span class="o">-</span>   <span class="n">Loading</span> <span class="n">features</span> <span class="kn">from</span> <span class="nn">cached</span> <span class="n">file</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span> <span class="p">[</span><span class="n">took</span> <span class="mf">0.006</span> <span class="n">s</span><span class="p">]</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">filelock</span> <span class="o">-</span>   <span class="n">Lock</span> <span class="mi">139826145788312</span> <span class="n">released</span> <span class="n">on</span> <span class="o">./</span><span class="n">wikitext</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">raw</span><span class="o">/</span><span class="n">cached_lm_GPT2TokenizerFast_1024_wiki</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">lock</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>   <span class="n">You</span> <span class="n">are</span> <span class="n">instantiating</span> <span class="n">a</span> <span class="n">Trainer</span> <span class="n">but</span> <span class="n">W</span><span class="o">&amp;</span><span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">installed</span><span class="o">.</span> <span class="n">To</span> <span class="n">use</span> <span class="n">wandb</span> <span class="n">logging</span><span class="p">,</span> <span class="n">run</span> <span class="err">`</span><span class="n">pip</span> <span class="n">install</span> <span class="n">wandb</span><span class="p">;</span> <span class="n">wandb</span> <span class="n">login</span><span class="err">`</span> <span class="n">see</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">docs</span><span class="o">.</span><span class="n">wandb</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">huggingface</span><span class="o">.</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>   <span class="o">*****</span> <span class="n">Running</span> <span class="n">training</span> <span class="o">*****</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Num</span> <span class="n">examples</span> <span class="o">=</span> <span class="mi">279</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Num</span> <span class="n">Epochs</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Instantaneous</span> <span class="n">batch</span> <span class="n">size</span> <span class="n">per</span> <span class="n">device</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Total</span> <span class="n">train</span> <span class="n">batch</span> <span class="n">size</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span> <span class="n">parallel</span><span class="p">,</span> <span class="n">distributed</span> <span class="o">&amp;</span> <span class="n">accumulation</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Gradient</span> <span class="n">Accumulation</span> <span class="n">steps</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">45</span><span class="p">:</span><span class="mi">45</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>     <span class="n">Total</span> <span class="n">optimization</span> <span class="n">steps</span> <span class="o">=</span> <span class="mi">279</span>
    <span class="n">Epoch</span><span class="p">:</span>   <span class="mi">0</span><span class="o">%|</span>          <span class="o">|</span> <span class="mi">0</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="err">?</span><span class="p">,</span> <span class="err">?</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
    <span class="n">Iteration</span><span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">279</span><span class="o">/</span><span class="mi">279</span> <span class="p">[</span><span class="mi">01</span><span class="p">:</span><span class="mi">04</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">4.33</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span><span class="err"></span><span class="p">[</span><span class="n">A</span>
    <span class="n">Epoch</span><span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">01</span><span class="p">:</span><span class="mi">04</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">64.48</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mi">49</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>   

    <span class="n">Training</span> <span class="n">completed</span><span class="o">.</span> <span class="n">Do</span> <span class="ow">not</span> <span class="n">forget</span> <span class="n">to</span> <span class="n">share</span> <span class="n">your</span> <span class="n">model</span> <span class="n">on</span> <span class="n">huggingface</span><span class="o">.</span><span class="n">co</span><span class="o">/</span><span class="n">models</span> <span class="o">=</span><span class="p">)</span>


    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mi">49</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">trainer</span> <span class="o">-</span>   <span class="n">Saving</span> <span class="n">model</span> <span class="n">checkpoint</span> <span class="n">to</span> <span class="o">./</span><span class="n">models</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mi">49</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">configuration_utils</span> <span class="o">-</span>   <span class="n">Configuration</span> <span class="n">saved</span> <span class="ow">in</span> <span class="o">./</span><span class="n">models</span><span class="o">/</span><span class="n">config</span><span class="o">.</span><span class="n">json</span>
    <span class="mi">08</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2020</span> <span class="mi">15</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mi">50</span> <span class="o">-</span> <span class="n">INFO</span> <span class="o">-</span> <span class="n">transformers</span><span class="o">.</span><span class="n">modeling_utils</span> <span class="o">-</span>   <span class="n">Model</span> <span class="n">weights</span> <span class="n">saved</span> <span class="ow">in</span> <span class="o">./</span><span class="n">models</span><span class="o">/</span><span class="n">pytorch_model</span><span class="o">.</span><span class="n">bin</span>
</code></pre></div>


</details>

<h1 id="3-language-model-evaluation">3. Language model evaluation<a class="headerlink" href="#3-language-model-evaluation" title="Permanent link">&para;</a></h1>
<p>To run evaluation on the model with your eval dataset, all you need to call is the built-in <code>finetuner.evaluate()</code>, since you've already loaded in your eval dataset during training.</p>
<div class="codehilite"><pre><span></span><code><span class="n">finetuner</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>
</code></pre></div>

<p>And now you have your very own pre-trained language model that's been fine-tuned on your personal domain data!</p>
<p>Since we've just fine-tuned a causal language model, we can actually load this straight into an <code>EasyTextGenerator</code> class object and play around with our language model to evaluate it qualitatively with our own "eyes".</p>
<p>All we have to do is pass in the directory that we've output our trained language model, in this case it's located in "./models"</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">adaptnlp</span> <span class="kn">import</span> <span class="n">EasyTextGenerator</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;China and the U.S. will begin to&quot;</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">EasyTextGenerator</span><span class="p">()</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># Generate</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">text</span><span class="p">,</span> 
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;./models&quot;</span><span class="p">,</span> 
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</code></pre></div>

<details class = "summary">
<summary>Output</summary>

<div class="codehilite"><pre><span></span><code>    <span class="n">Generating</span><span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">2.26</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>

    <span class="p">[</span><span class="s1">&#39;China and the U.S. will begin to develop their own nuclear weapons in the coming years.</span><span class="se">\n\n</span><span class="s1">The U.S. has been developing a range of nuclear weapons since the 1950s, but the U.S. has never used them in combat. The U.S. has been&#39;</span><span class="p">]</span>
</code></pre></div>


</details>

<p>You can compare this with the original pre-trained gpt2 model as well. </p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Generate</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">text</span><span class="p">,</span> 
    <span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> 
    <span class="n">num_tokens_to_produce</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</code></pre></div>

<details class = "summary">
<summary>Output</summary>

<div class="codehilite"><pre><span></span><code>    <span class="n">Special</span> <span class="n">tokens</span> <span class="n">have</span> <span class="n">been</span> <span class="n">added</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">make</span> <span class="n">sure</span> <span class="n">the</span> <span class="n">associated</span> <span class="n">word</span> <span class="n">emebedding</span> <span class="n">are</span> <span class="n">fine</span><span class="o">-</span><span class="n">tuned</span> <span class="ow">or</span> <span class="n">trained</span><span class="o">.</span>
    <span class="n">Some</span> <span class="n">weights</span> <span class="n">of</span> <span class="n">GPT2LMHeadModel</span> <span class="n">were</span> <span class="ow">not</span> <span class="n">initialized</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">model</span> <span class="n">checkpoint</span> <span class="n">at</span> <span class="n">gpt2</span> <span class="ow">and</span> <span class="n">are</span> <span class="n">newly</span> <span class="n">initialized</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;h.0.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.1.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.2.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.3.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.4.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.5.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.6.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.7.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.8.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.9.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.10.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;h.11.attn.masked_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;lm_head.weight&#39;</span><span class="p">]</span>
    <span class="n">You</span> <span class="n">should</span> <span class="n">probably</span> <span class="n">TRAIN</span> <span class="n">this</span> <span class="n">model</span> <span class="n">on</span> <span class="n">a</span> <span class="n">down</span><span class="o">-</span><span class="n">stream</span> <span class="n">task</span> <span class="n">to</span> <span class="n">be</span> <span class="n">able</span> <span class="n">to</span> <span class="n">use</span> <span class="n">it</span> <span class="k">for</span> <span class="n">predictions</span> <span class="ow">and</span> <span class="n">inference</span><span class="o">.</span>
    <span class="n">Generating</span><span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">2.33</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>

    <span class="p">[</span><span class="s1">&#39;China and the U.S. will begin to see the effects of the new sanctions on the Russian economy.</span><span class="se">\n\n</span><span class="s1">&quot;The U.S. is going to be the first to see the effects of the new sanctions,&quot; said Michael O</span><span class="se">\&#39;</span><span class="s1">Hanlon, a senior fellow at the Center for Strategic&#39;</span><span class="p">]</span>
</code></pre></div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="training-sequence-classification.html" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Training Sequence Classification
            </div>
          </div>
        </a>
      
      
        <a href="../rest.html" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              NLP Services with FastAPI
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fb4a9340.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.ca5457b8.min.js"></script>
      
    
  </body>
</html>